{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharmashubham240496/KNN/blob/main/KNN_Small_dataset_backward_Elimination.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Implement Feature Search (using Nearest Neighbor Backward Elimination) on Small Dataset"
      ],
      "metadata": {
        "id": "j8ZjcP00SsvJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3IrV8O8_Bz5",
        "outputId": "cfb7dc3d-55dd-4304-e5e2-8888cfdd3f0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-3eecd6aea3ec>:12: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  small_df = pd.read_csv(small_file_path, delimiter='  ', header=None)\n"
          ]
        }
      ],
      "source": [
        "#Birth date          - 24/04/1996\n",
        "#Birth Day           - Reading the dataset small data 24th number file from google drive\n",
        "\n",
        "from google.colab import drive\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "small_file_path = '/content/drive/MyDrive/Assignment_Knn/KNN_dataset_files/CS170_small_Data__24.txt'\n",
        "\n",
        "small_df = pd.read_csv(small_file_path, delimiter='  ', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "small_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UrUGnvMcwP3",
        "outputId": "c7016eab-e086-419f-bd3e-f5c2f7d5c277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dataset_normalization(input_dataset):\n",
        "  # Z normalization on all the columns of the dataset except 1st column as it is the lable column\n",
        "  input_data_array = input_dataset.values\n",
        "  columns_to_normalize_except_label = np.arange(1, input_data_array.shape[1])\n",
        "\n",
        "  #calculating the mean and standard deviation for each column except lable column\n",
        "  columns_respective_means = np.mean(input_data_array[:, columns_to_normalize_except_label], axis=0)\n",
        "  columns_respective_stds = np.std(input_data_array[:, columns_to_normalize_except_label], axis=0)\n",
        "\n",
        "  input_data_array[:, columns_to_normalize_except_label] = (input_data_array[:, columns_to_normalize_except_label] - columns_respective_means) / columns_respective_stds\n",
        "\n",
        "  input_dataset_normalized = pd.DataFrame(input_data_array, columns=input_dataset.columns)\n",
        "\n",
        "  return input_dataset_normalized"
      ],
      "metadata": {
        "id": "1atgNzEALC7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def evaluating_accuracy(normalized_input_dataset):\n",
        "    number_of_correctly_classified_labels = 0\n",
        "    X = normalized_input_dataset[:, 1:]\n",
        "    y = normalized_input_dataset[:, 0]\n",
        "\n",
        "    for i in range(len(normalized_input_dataset)):\n",
        "        current_row_label = y[i]\n",
        "        current_row_classification = X[i]\n",
        "\n",
        "        current_row_nearest_neighbor_distance = float('inf')\n",
        "        nearest_neighbor_encountered_label = None\n",
        "\n",
        "        for j in range(len(normalized_input_dataset)):\n",
        "            if i != j:\n",
        "                euclidean_distance = np.sqrt(np.sum((current_row_classification - X[j])**2))\n",
        "\n",
        "                if euclidean_distance < current_row_nearest_neighbor_distance:\n",
        "                    current_row_nearest_neighbor_distance = euclidean_distance\n",
        "                    nearest_neighbor_encountered_label = y[j]\n",
        "\n",
        "        if nearest_neighbor_encountered_label == current_row_label:\n",
        "            number_of_correctly_classified_labels += 1\n",
        "\n",
        "    classifier_accuracy_evaluation_metric = number_of_correctly_classified_labels / len(normalized_input_dataset)\n",
        "\n",
        "    return classifier_accuracy_evaluation_metric * 100"
      ],
      "metadata": {
        "id": "agpYpEXgLHMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backward_elimination(normalized_input_dataset):\n",
        "    print(\"Beginning Search\")\n",
        "    all_feature_set = list(range(1, normalized_input_dataset.shape[1]))\n",
        "    feature_set = {}\n",
        "\n",
        "    X = normalized_input_dataset.values\n",
        "\n",
        "    accuracy_value = evaluating_accuracy(X)\n",
        "    print(\"all features\", tuple(all_feature_set),\"accuracy is\", accuracy_value)\n",
        "\n",
        "\n",
        "    while len(all_feature_set) != 1:\n",
        "        feature_dict = {}\n",
        "        for c in all_feature_set:\n",
        "            temp_ls = all_feature_set.copy()\n",
        "            temp_ls.remove(c)\n",
        "            columns_to_include = [0] + temp_ls\n",
        "            evaluating_performance_dataset = X[:, columns_to_include]\n",
        "            accuracy_value = evaluating_accuracy(evaluating_performance_dataset)\n",
        "            columns_to_include.remove(0)\n",
        "\n",
        "            print()\n",
        "            print(\"Using feature(s)\", tuple(columns_to_include), \"accuracy is\", accuracy_value)\n",
        "            feature_dict[tuple(columns_to_include)] = accuracy_value\n",
        "\n",
        "        print()\n",
        "        max_key = max(feature_dict, key=feature_dict.get)\n",
        "        feature_value = list(set(all_feature_set) - set(max_key))[0]\n",
        "        print(\"Feature set\", tuple(max_key), \"was best, accuracy is\", feature_dict[max_key], \"eliminating feature is\", feature_value)\n",
        "        print()\n",
        "\n",
        "        all_feature_set.remove(feature_value)\n",
        "        feature_set[max_key] = feature_dict[max_key]\n",
        "\n",
        "    best_feature_list = max(feature_set, key=feature_set.get)\n",
        "\n",
        "    print()\n",
        "    print(\"Finished search!! The best feature subset is\", tuple(best_feature_list), \"which has an accuracy of\", feature_set[best_feature_list])\n",
        "    return None"
      ],
      "metadata": {
        "id": "TlVIoOooO0cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "small_normalized_df = dataset_normalization(small_df)\n",
        "backward_elimination(small_normalized_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DVSvVbrLchE",
        "outputId": "b500b61c-4372-4110-cb8e-8e592763a44e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beginning Search\n",
            "all features (1, 2, 3, 4, 5, 6, 7, 8, 9, 10) accuracy is 78.5\n",
            "\n",
            "Using feature(s) (2, 3, 4, 5, 6, 7, 8, 9, 10) accuracy is 79.80000000000001\n",
            "\n",
            "Using feature(s) (1, 3, 4, 5, 6, 7, 8, 9, 10) accuracy is 79.7\n",
            "\n",
            "Using feature(s) (1, 2, 4, 5, 6, 7, 8, 9, 10) accuracy is 72.39999999999999\n",
            "\n",
            "Using feature(s) (1, 2, 3, 5, 6, 7, 8, 9, 10) accuracy is 78.5\n",
            "\n",
            "Using feature(s) (1, 2, 3, 4, 6, 7, 8, 9, 10) accuracy is 80.60000000000001\n",
            "\n",
            "Using feature(s) (1, 2, 3, 4, 5, 7, 8, 9, 10) accuracy is 76.6\n",
            "\n",
            "Using feature(s) (1, 2, 3, 4, 5, 6, 8, 9, 10) accuracy is 79.4\n",
            "\n",
            "Using feature(s) (1, 2, 3, 4, 5, 6, 7, 9, 10) accuracy is 79.60000000000001\n",
            "\n",
            "Using feature(s) (1, 2, 3, 4, 5, 6, 7, 8, 10) accuracy is 79.5\n",
            "\n",
            "Using feature(s) (1, 2, 3, 4, 5, 6, 7, 8, 9) accuracy is 78.9\n",
            "\n",
            "Feature set (1, 2, 3, 4, 6, 7, 8, 9, 10) was best, accuracy is 80.60000000000001 eliminating feature is 5\n",
            "\n",
            "\n",
            "Using feature(s) (2, 3, 4, 6, 7, 8, 9, 10) accuracy is 80.7\n",
            "\n",
            "Using feature(s) (1, 3, 4, 6, 7, 8, 9, 10) accuracy is 81.8\n",
            "\n",
            "Using feature(s) (1, 2, 4, 6, 7, 8, 9, 10) accuracy is 73.2\n",
            "\n",
            "Using feature(s) (1, 2, 3, 6, 7, 8, 9, 10) accuracy is 79.80000000000001\n",
            "\n",
            "Using feature(s) (1, 2, 3, 4, 7, 8, 9, 10) accuracy is 77.0\n",
            "\n",
            "Using feature(s) (1, 2, 3, 4, 6, 8, 9, 10) accuracy is 81.0\n",
            "\n",
            "Using feature(s) (1, 2, 3, 4, 6, 7, 9, 10) accuracy is 81.10000000000001\n",
            "\n",
            "Using feature(s) (1, 2, 3, 4, 6, 7, 8, 10) accuracy is 81.39999999999999\n",
            "\n",
            "Using feature(s) (1, 2, 3, 4, 6, 7, 8, 9) accuracy is 80.60000000000001\n",
            "\n",
            "Feature set (1, 3, 4, 6, 7, 8, 9, 10) was best, accuracy is 81.8 eliminating feature is 2\n",
            "\n",
            "\n",
            "Using feature(s) (3, 4, 6, 7, 8, 9, 10) accuracy is 82.89999999999999\n",
            "\n",
            "Using feature(s) (1, 4, 6, 7, 8, 9, 10) accuracy is 73.0\n",
            "\n",
            "Using feature(s) (1, 3, 6, 7, 8, 9, 10) accuracy is 82.6\n",
            "\n",
            "Using feature(s) (1, 3, 4, 7, 8, 9, 10) accuracy is 78.10000000000001\n",
            "\n",
            "Using feature(s) (1, 3, 4, 6, 8, 9, 10) accuracy is 80.9\n",
            "\n",
            "Using feature(s) (1, 3, 4, 6, 7, 9, 10) accuracy is 82.5\n",
            "\n",
            "Using feature(s) (1, 3, 4, 6, 7, 8, 10) accuracy is 82.39999999999999\n",
            "\n",
            "Using feature(s) (1, 3, 4, 6, 7, 8, 9) accuracy is 82.19999999999999\n",
            "\n",
            "Feature set (3, 4, 6, 7, 8, 9, 10) was best, accuracy is 82.89999999999999 eliminating feature is 1\n",
            "\n",
            "\n",
            "Using feature(s) (4, 6, 7, 8, 9, 10) accuracy is 74.0\n",
            "\n",
            "Using feature(s) (3, 6, 7, 8, 9, 10) accuracy is 83.6\n",
            "\n",
            "Using feature(s) (3, 4, 7, 8, 9, 10) accuracy is 78.0\n",
            "\n",
            "Using feature(s) (3, 4, 6, 8, 9, 10) accuracy is 82.69999999999999\n",
            "\n",
            "Using feature(s) (3, 4, 6, 7, 9, 10) accuracy is 83.7\n",
            "\n",
            "Using feature(s) (3, 4, 6, 7, 8, 10) accuracy is 85.6\n",
            "\n",
            "Using feature(s) (3, 4, 6, 7, 8, 9) accuracy is 82.8\n",
            "\n",
            "Feature set (3, 4, 6, 7, 8, 10) was best, accuracy is 85.6 eliminating feature is 9\n",
            "\n",
            "\n",
            "Using feature(s) (4, 6, 7, 8, 10) accuracy is 74.3\n",
            "\n",
            "Using feature(s) (3, 6, 7, 8, 10) accuracy is 88.4\n",
            "\n",
            "Using feature(s) (3, 4, 7, 8, 10) accuracy is 80.7\n",
            "\n",
            "Using feature(s) (3, 4, 6, 8, 10) accuracy is 88.7\n",
            "\n",
            "Using feature(s) (3, 4, 6, 7, 10) accuracy is 87.5\n",
            "\n",
            "Using feature(s) (3, 4, 6, 7, 8) accuracy is 86.4\n",
            "\n",
            "Feature set (3, 4, 6, 8, 10) was best, accuracy is 88.7 eliminating feature is 7\n",
            "\n",
            "\n",
            "Using feature(s) (4, 6, 8, 10) accuracy is 75.5\n",
            "\n",
            "Using feature(s) (3, 6, 8, 10) accuracy is 87.7\n",
            "\n",
            "Using feature(s) (3, 4, 8, 10) accuracy is 82.89999999999999\n",
            "\n",
            "Using feature(s) (3, 4, 6, 10) accuracy is 90.3\n",
            "\n",
            "Using feature(s) (3, 4, 6, 8) accuracy is 90.0\n",
            "\n",
            "Feature set (3, 4, 6, 10) was best, accuracy is 90.3 eliminating feature is 8\n",
            "\n",
            "\n",
            "Using feature(s) (4, 6, 10) accuracy is 73.4\n",
            "\n",
            "Using feature(s) (3, 6, 10) accuracy is 93.4\n",
            "\n",
            "Using feature(s) (3, 4, 10) accuracy is 84.6\n",
            "\n",
            "Using feature(s) (3, 4, 6) accuracy is 91.7\n",
            "\n",
            "Feature set (3, 6, 10) was best, accuracy is 93.4 eliminating feature is 4\n",
            "\n",
            "\n",
            "Using feature(s) (6, 10) accuracy is 76.4\n",
            "\n",
            "Using feature(s) (3, 10) accuracy is 85.7\n",
            "\n",
            "Using feature(s) (3, 6) accuracy is 97.3\n",
            "\n",
            "Feature set (3, 6) was best, accuracy is 97.3 eliminating feature is 10\n",
            "\n",
            "\n",
            "Using feature(s) (6,) accuracy is 76.0\n",
            "\n",
            "Using feature(s) (3,) accuracy is 86.7\n",
            "\n",
            "Feature set (3,) was best, accuracy is 86.7 eliminating feature is 6\n",
            "\n",
            "\n",
            "Finished search!! The best feature subset is (3, 6) which has an accuracy of 97.3\n",
            "CPU times: user 8min 9s, sys: 1.25 s, total: 8min 10s\n",
            "Wall time: 8min 20s\n"
          ]
        }
      ]
    }
  ]
}