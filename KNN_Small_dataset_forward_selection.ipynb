{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharmashubham240496/KNN/blob/main/KNN_Small_dataset_forward_selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Implement Feature Search (using Nearest Neighbor Forward Selection) on Small Dataset"
      ],
      "metadata": {
        "id": "VkR7Eq4wLIJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Birth date          - 24/04/1996\n",
        "#Birth Day           - Reading the dataset small data 24th number file from google drive\n",
        "#Birth Month         - Reading the dataset large data 4th number file from google drive\n",
        "#Birth Month + Month - Reading the dataset xxxlarge data 8th number file from google drive\n",
        "\n",
        "from google.colab import drive\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "small_file_path = '/content/drive/MyDrive/Assignment_Knn/KNN_dataset_files/CS170_small_Data__24.txt'\n",
        "\n",
        "small_df = pd.read_csv(small_file_path, delimiter='  ', header=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYpU09WfLHsh",
        "outputId": "dd7fa912-91f7-49ff-a094-105fa0b87d1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-9226b4b6ef06>:14: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  small_df = pd.read_csv(small_file_path, delimiter='  ', header=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dataset_normalization(input_dataset):\n",
        "  # Z normalization on all the columns of the dataset except 1st column as it is the lable column\n",
        "  input_data_array = input_dataset.values\n",
        "  columns_to_normalize_except_label = np.arange(1, input_data_array.shape[1])\n",
        "\n",
        "  #calculating the mean and standard deviation for each column except lable column\n",
        "  columns_respective_means = np.mean(input_data_array[:, columns_to_normalize_except_label], axis=0)\n",
        "  columns_respective_stds = np.std(input_data_array[:, columns_to_normalize_except_label], axis=0)\n",
        "\n",
        "  input_data_array[:, columns_to_normalize_except_label] = (input_data_array[:, columns_to_normalize_except_label] - columns_respective_means) / columns_respective_stds\n",
        "\n",
        "  input_dataset_normalized = pd.DataFrame(input_data_array, columns=input_dataset.columns)\n",
        "\n",
        "  return input_dataset_normalized"
      ],
      "metadata": {
        "id": "3oxdOZqvLXb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def evaluating_accuracy(normalized_input_dataset):\n",
        "    number_of_correctly_classified_labels = 0\n",
        "    X = normalized_input_dataset[:, 1:]\n",
        "    y = normalized_input_dataset[:, 0]\n",
        "\n",
        "    for i in range(len(normalized_input_dataset)):\n",
        "        current_row_label = y[i]\n",
        "        current_row_classification = X[i]\n",
        "\n",
        "        current_row_nearest_neighbor_distance = float('inf')\n",
        "        nearest_neighbor_encountered_label = None\n",
        "\n",
        "        for j in range(len(normalized_input_dataset)):\n",
        "            if i != j:\n",
        "                euclidean_distance = np.sqrt(np.sum((current_row_classification - X[j])**2))\n",
        "\n",
        "                if euclidean_distance < current_row_nearest_neighbor_distance:\n",
        "                    current_row_nearest_neighbor_distance = euclidean_distance\n",
        "                    nearest_neighbor_encountered_label = y[j]\n",
        "\n",
        "        if nearest_neighbor_encountered_label == current_row_label:\n",
        "            number_of_correctly_classified_labels += 1\n",
        "\n",
        "    classifier_accuracy_evaluation_metric = number_of_correctly_classified_labels / len(normalized_input_dataset)\n",
        "\n",
        "    return classifier_accuracy_evaluation_metric * 100"
      ],
      "metadata": {
        "id": "jPwSSfHgLZtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_selection(normalized_input_dataset):\n",
        "    print(\"Beginning Search\")\n",
        "    selected_feature_set = []\n",
        "    remaining_feature_set = list(range(1, normalized_input_dataset.shape[1]))\n",
        "    feature_set = {}\n",
        "\n",
        "    X = normalized_input_dataset.values\n",
        "\n",
        "    while len(remaining_feature_set) != 0:\n",
        "        feature_dict = {}\n",
        "\n",
        "        for c in remaining_feature_set:\n",
        "            columns_to_include = [0] + [c] + selected_feature_set\n",
        "            evaluating_performance_dataset = X[:, columns_to_include]\n",
        "            accuracy_value = evaluating_accuracy(evaluating_performance_dataset)\n",
        "            columns_to_include.remove(0)\n",
        "\n",
        "            print()\n",
        "            print(\"Using feature(s)\", tuple(columns_to_include), \"accuracy is\", accuracy_value)\n",
        "            feature_dict[tuple(columns_to_include)] = accuracy_value\n",
        "\n",
        "        print()\n",
        "        max_key = max(feature_dict, key=feature_dict.get)\n",
        "        print(\"Feature set\", tuple(max_key), \"was best, accuracy is\", feature_dict[max_key])\n",
        "        print()\n",
        "\n",
        "        selected_feature_set.insert(0, max_key[0])\n",
        "        remaining_feature_set.remove(max_key[0])\n",
        "        feature_set[max_key] = feature_dict[max_key]\n",
        "\n",
        "    best_feature_list = max(feature_set, key=feature_set.get)\n",
        "\n",
        "    print()\n",
        "    print(\"Finished search!! The best feature subset is\", tuple(best_feature_list), \"which has an accuracy of\", feature_set[best_feature_list])\n",
        "    return None"
      ],
      "metadata": {
        "id": "aNgFq3hjLk9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "small_normalized_df = dataset_normalization(small_df)\n",
        "forward_selection(small_normalized_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rBX9_bfU_LF",
        "outputId": "012474fd-e107-4127-94f0-964bf81b7a29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beginning Search\n",
            "\n",
            "Using feature(s) (1,) accuracy is 72.3\n",
            "\n",
            "Using feature(s) (2,) accuracy is 72.5\n",
            "\n",
            "Using feature(s) (3,) accuracy is 86.7\n",
            "\n",
            "Using feature(s) (4,) accuracy is 71.5\n",
            "\n",
            "Using feature(s) (5,) accuracy is 70.7\n",
            "\n",
            "Using feature(s) (6,) accuracy is 76.0\n",
            "\n",
            "Using feature(s) (7,) accuracy is 71.6\n",
            "\n",
            "Using feature(s) (8,) accuracy is 71.0\n",
            "\n",
            "Using feature(s) (9,) accuracy is 70.6\n",
            "\n",
            "Using feature(s) (10,) accuracy is 70.19999999999999\n",
            "\n",
            "Feature set (3,) was best, accuracy is 86.7\n",
            "\n",
            "\n",
            "Using feature(s) (1, 3) accuracy is 87.1\n",
            "\n",
            "Using feature(s) (2, 3) accuracy is 85.6\n",
            "\n",
            "Using feature(s) (4, 3) accuracy is 83.89999999999999\n",
            "\n",
            "Using feature(s) (5, 3) accuracy is 83.89999999999999\n",
            "\n",
            "Using feature(s) (6, 3) accuracy is 97.3\n",
            "\n",
            "Using feature(s) (7, 3) accuracy is 84.7\n",
            "\n",
            "Using feature(s) (8, 3) accuracy is 82.5\n",
            "\n",
            "Using feature(s) (9, 3) accuracy is 84.6\n",
            "\n",
            "Using feature(s) (10, 3) accuracy is 85.7\n",
            "\n",
            "Feature set (6, 3) was best, accuracy is 97.3\n",
            "\n",
            "\n",
            "Using feature(s) (1, 6, 3) accuracy is 95.3\n",
            "\n",
            "Using feature(s) (2, 6, 3) accuracy is 92.9\n",
            "\n",
            "Using feature(s) (4, 6, 3) accuracy is 91.7\n",
            "\n",
            "Using feature(s) (5, 6, 3) accuracy is 93.30000000000001\n",
            "\n",
            "Using feature(s) (7, 6, 3) accuracy is 94.19999999999999\n",
            "\n",
            "Using feature(s) (8, 6, 3) accuracy is 93.5\n",
            "\n",
            "Using feature(s) (9, 6, 3) accuracy is 91.3\n",
            "\n",
            "Using feature(s) (10, 6, 3) accuracy is 93.4\n",
            "\n",
            "Feature set (1, 6, 3) was best, accuracy is 95.3\n",
            "\n",
            "\n",
            "Using feature(s) (2, 1, 6, 3) accuracy is 91.4\n",
            "\n",
            "Using feature(s) (4, 1, 6, 3) accuracy is 90.7\n",
            "\n",
            "Using feature(s) (5, 1, 6, 3) accuracy is 90.8\n",
            "\n",
            "Using feature(s) (7, 1, 6, 3) accuracy is 92.4\n",
            "\n",
            "Using feature(s) (8, 1, 6, 3) accuracy is 90.4\n",
            "\n",
            "Using feature(s) (9, 1, 6, 3) accuracy is 90.7\n",
            "\n",
            "Using feature(s) (10, 1, 6, 3) accuracy is 92.30000000000001\n",
            "\n",
            "Feature set (7, 1, 6, 3) was best, accuracy is 92.4\n",
            "\n",
            "\n",
            "Using feature(s) (2, 7, 1, 6, 3) accuracy is 87.9\n",
            "\n",
            "Using feature(s) (4, 7, 1, 6, 3) accuracy is 87.3\n",
            "\n",
            "Using feature(s) (5, 7, 1, 6, 3) accuracy is 86.9\n",
            "\n",
            "Using feature(s) (8, 7, 1, 6, 3) accuracy is 88.2\n",
            "\n",
            "Using feature(s) (9, 7, 1, 6, 3) accuracy is 87.7\n",
            "\n",
            "Using feature(s) (10, 7, 1, 6, 3) accuracy is 88.0\n",
            "\n",
            "Feature set (8, 7, 1, 6, 3) was best, accuracy is 88.2\n",
            "\n",
            "\n",
            "Using feature(s) (2, 8, 7, 1, 6, 3) accuracy is 82.8\n",
            "\n",
            "Using feature(s) (4, 8, 7, 1, 6, 3) accuracy is 85.2\n",
            "\n",
            "Using feature(s) (5, 8, 7, 1, 6, 3) accuracy is 84.2\n",
            "\n",
            "Using feature(s) (9, 8, 7, 1, 6, 3) accuracy is 83.8\n",
            "\n",
            "Using feature(s) (10, 8, 7, 1, 6, 3) accuracy is 85.5\n",
            "\n",
            "Feature set (10, 8, 7, 1, 6, 3) was best, accuracy is 85.5\n",
            "\n",
            "\n",
            "Using feature(s) (2, 10, 8, 7, 1, 6, 3) accuracy is 83.1\n",
            "\n",
            "Using feature(s) (4, 10, 8, 7, 1, 6, 3) accuracy is 82.39999999999999\n",
            "\n",
            "Using feature(s) (5, 10, 8, 7, 1, 6, 3) accuracy is 83.8\n",
            "\n",
            "Using feature(s) (9, 10, 8, 7, 1, 6, 3) accuracy is 82.6\n",
            "\n",
            "Feature set (5, 10, 8, 7, 1, 6, 3) was best, accuracy is 83.8\n",
            "\n",
            "\n",
            "Using feature(s) (2, 5, 10, 8, 7, 1, 6, 3) accuracy is 80.60000000000001\n",
            "\n",
            "Using feature(s) (4, 5, 10, 8, 7, 1, 6, 3) accuracy is 83.0\n",
            "\n",
            "Using feature(s) (9, 5, 10, 8, 7, 1, 6, 3) accuracy is 80.0\n",
            "\n",
            "Feature set (4, 5, 10, 8, 7, 1, 6, 3) was best, accuracy is 83.0\n",
            "\n",
            "\n",
            "Using feature(s) (2, 4, 5, 10, 8, 7, 1, 6, 3) accuracy is 79.5\n",
            "\n",
            "Using feature(s) (9, 4, 5, 10, 8, 7, 1, 6, 3) accuracy is 79.7\n",
            "\n",
            "Feature set (9, 4, 5, 10, 8, 7, 1, 6, 3) was best, accuracy is 79.7\n",
            "\n",
            "\n",
            "Using feature(s) (2, 9, 4, 5, 10, 8, 7, 1, 6, 3) accuracy is 78.5\n",
            "\n",
            "Feature set (2, 9, 4, 5, 10, 8, 7, 1, 6, 3) was best, accuracy is 78.5\n",
            "\n",
            "\n",
            "Finished search!! The best feature subset is (6, 3) which has an accuracy of 97.3\n",
            "CPU times: user 5min 18s, sys: 618 ms, total: 5min 19s\n",
            "Wall time: 5min 22s\n"
          ]
        }
      ]
    }
  ]
}